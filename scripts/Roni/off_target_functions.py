from asodesigner.fold import get_trigger_mfe_scores_by_risearch
from Bio import SeqIO
import pandas as pd
from io import StringIO
import os
import pickle


def dna_to_rna_reverse_complement(seq: str) -> str:
    seq = seq.upper()
    translation_table = str.maketrans("ATGC", "UACG")
    # Translate and reverse
    return seq.translate(translation_table)[::-1]


def normalize_chrom(chrom: str) -> str:
    # Lowercase safe removal of exact "chr" prefix only
    if chrom.lower().startswith("chr"):
        chrom = chrom[3:]

    # Mitochondrial chromosome normalization
    if chrom in {"M", "m"}:
        return "MT"

    return chrom

def get_min_max_coords(tup_list):
    flatt = (x for tup in tup_list for x in tup)
    abs_min = abs_max = next(flatt)

    for x in flatt:
        if x < abs_min:
            abs_min = x
        if x > abs_max:
            abs_max = x

    return (abs_min, abs_max)

def parse_risearch_output(output_str: str) -> pd.DataFrame:
    columns = ["trigger", "trigger_start", "trigger_end", "target", "target_start", "target_end", "score", "energy"]
    df = pd.read_csv(StringIO(output_str.strip()), sep="\t", header=None, names=columns)
    return df

def aggregate_off_targets(df: pd.DataFrame) -> pd.DataFrame:
    # Aggregate: sum score (if it's hybridization hits) and take minimum (strongest) energy
    grouped = df.groupby("target").agg({
        "score": "sum",
        "energy": "min"
    }).reset_index()
    return grouped

def parse_gtf(gtf_path, cache_path=None):
    import pickle, os

    if not cache_path:
        cache_path = os.path.splitext(os.path.basename(gtf_path))[0] + "_gtf_annotations.pkl"

    if os.path.exists(cache_path):
        with open(cache_path, 'rb') as f:
            return pickle.load(f)

    annotations = {}
    with open(gtf_path) as f:
        for line in f:
            if line.startswith("#"):
                continue
            fields = line.strip().split("\t")
            if len(fields) != 9:
                continue

            chrom, source, feature, start, end, score, strand, frame, attributes = fields
            if feature not in ["exon", "CDS", "UTR"]:
                continue

            attr_dict = {
                key: val.strip('"') for key, val in
                [attr.strip().split(' ') for attr in attributes.split(';') if attr.strip()]
            }
            transcript_id = attr_dict.get("transcript_id")
            if not transcript_id:
                continue

            start, end = int(start), int(end)

            if transcript_id not in annotations:
                annotations[transcript_id] = {
                    "chrom": chrom,
                    "strand": strand,
                    "exons": [],
                    "cds": [],
                    "utrs": [],
                    "feature_coords": []  # will collect all coords for accurate span
                }

            # Add to appropriate list
            feature_map = {
                "exon": "exons",
                "CDS": "cds",
                "UTR": "utrs"
            }
            key = feature_map.get(feature)
            if key:
                annotations[transcript_id][key].append((start, end))

            # Collect for overall start/end calculation
            annotations[transcript_id]["feature_coords"].append((start, end))

    # Now compute correct start/end from all features
    for coords in annotations.values():
        coords['start'], coords['end'] = get_min_max_coords(coords['feature_coords'])

    with open(cache_path, 'wb') as f:
        pickle.dump(annotations, f)

    return annotations


def parse_fasta(fasta_path, output_pickle):
    fasta_dict = {}

    for record in SeqIO.parse(fasta_path, "fasta"):
        chrom_id = record.id.split()[0]  # e.g., "1", "KI270728.1", "GL000225.1"
        fasta_dict[chrom_id] = str(record.seq).upper()

    print(f"âœ… Saved {len(fasta_dict)} main chromosomes to {output_pickle}")
    with open(output_pickle, "wb") as f:
        pickle.dump(fasta_dict, f)

name2accession = {
    'chr1':  'CM000663.2',
    'chr2':  'CM000664.2',
    'chr3':  'CM000665.2',
    'chr4':  'CM000666.2',
    'chr5':  'CM000667.2',
    'chr6':  'CM000668.2',
    'chr7':  'CM000669.2',
    'chr8':  'CM000670.2',
    'chr9':  'CM000671.2',
    'chr10': 'CM000672.2',
    'chr11': 'CM000673.2',
    'chr12': 'CM000674.2',
    'chr13': 'CM000675.2',
    'chr14': 'CM000676.2',
    'chr15': 'CM000677.2',
    'chr16': 'CM000678.2',
    'chr17': 'CM000679.2',
    'chr18': 'CM000680.2',
    'chr19': 'CM000681.2',
    'chr20': 'CM000682.2',
    'chr21': 'CM000683.2',
    'chr22': 'CM000684.2',
    'chrX':  'CM000685.2',
    'chrY':  'CM000686.2',
    'chrM': 'NC_012920.1'
}
