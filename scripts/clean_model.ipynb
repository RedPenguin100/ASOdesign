{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e0823384ae0a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T21:36:31.301082Z",
     "start_time": "2025-04-18T21:36:30.912231Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "from consts import *\n",
    "from file_utils import read_human_genome_fasta_dict\n",
    "\n",
    "all_data = pandas.read_csv(DATA_PATH / 'data_from_article_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04d398807497922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T21:36:31.311733Z",
     "start_time": "2025-04-18T21:36:31.307381Z"
    }
   },
   "outputs": [],
   "source": [
    "from data_genertion.consts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94829dab67b5c23e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T21:36:31.388936Z",
     "start_time": "2025-04-18T21:36:31.387215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature generation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7086cb42d5d2391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "all_data_no_nan = all_data.dropna(subset=[INHIBITION]).copy()\n",
    "all_data_no_nan.loc[:, 'log_inhibition'] = -np.log(-all_data_no_nan[INHIBITION] + 100.001)"
   ],
   "id": "1de6a0884ab0cda4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "all_data_no_nan_human = all_data_no_nan[all_data_no_nan[CELL_LINE_ORGANISM] == 'human']\n",
    "genes = all_data_no_nan[CANONICAL_GENE].copy()\n",
    "genes_u = list(set(genes))\n",
    "genes_u.remove('HBV')\n",
    "genes_u.remove('negative_control')"
   ],
   "id": "6e3735ce61c549cb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5f1bb7bdfeb283d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-18T21:44:23.161003Z",
     "start_time": "2025-04-18T21:43:56.758875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time took to read fasta: 10.494274854660034\n",
      "Length:  639\n"
     ]
    }
   ],
   "source": [
    "from read_human_genome import get_locus_to_data_dict\n",
    "import pickle\n",
    "from consts import CACHE_DIR\n",
    "\n",
    "\n",
    "cache_path = CACHE_DIR / 'gene_to_data_simple_cache.pickle'\n",
    "if not cache_path.exists():\n",
    "    gene_to_data = get_locus_to_data_dict(include_introns=True, gene_subset=genes_u)\n",
    "    with open(cache_path, 'wb') as f:\n",
    "        pickle.dump(gene_to_data, f)\n",
    "else:\n",
    "    with open(cache_path, 'rb') as f:\n",
    "        gene_to_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ce5bc32d3636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asodesigner.util import get_antisense\n",
    "\n",
    "all_data_human_gene = all_data_no_nan_human[all_data_no_nan_human[CANONICAL_GENE].isin(genes_u)].copy()\n",
    "PREMRNA_FOUND = 'pre_mrna_found'\n",
    "SENSE_START = 'sense_start'\n",
    "SENSE_LENGTH = 'sense_length'\n",
    "SENSE_TYPE = 'sense_type'\n",
    "\n",
    "found = 0\n",
    "not_found = 0\n",
    "all_data_human_gene[SENSE_START] = np.zeros_like(all_data_human_gene[CANONICAL_GENE], dtype=int)\n",
    "all_data_human_gene[SENSE_LENGTH] = np.zeros_like(all_data_human_gene[CANONICAL_GENE], dtype=int)\n",
    "all_data_human_gene[SENSE_TYPE] = \"NA\"\n",
    "for index, row in all_data_human_gene.iterrows():\n",
    "     gene_name = row[CANONICAL_GENE]\n",
    "     locus_info = gene_to_data[gene_name]\n",
    "     pre_mrna = locus_info.full_mrna\n",
    "     antisense = row[SEQUENCE]\n",
    "     sense = get_antisense(antisense)\n",
    "     idx = pre_mrna.find(sense)\n",
    "     all_data_human_gene.loc[index, SENSE_START] = idx\n",
    "     all_data_human_gene.loc[index, SENSE_LENGTH] = len(antisense)\n",
    "     if idx != -1:\n",
    "         genome_corrected_index = idx + locus_info.exon_indices[0][0]\n",
    "         found = False\n",
    "         for exon_indices in locus_info.exon_indices:\n",
    "            # print(exon[0], exon[1])\n",
    "            if exon_indices[0] <=  genome_corrected_index <= exon_indices[1]:\n",
    "                all_data_human_gene.loc[index, SENSE_TYPE] = 'exon'\n",
    "                found = True\n",
    "                break\n",
    "     if not found:\n",
    "         all_data_human_gene.loc[index, SENSE_TYPE] = 'intron'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80e20168355323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter genes that were not found in genome\n",
    "all_data_human_gene_premrna = all_data_human_gene[all_data_human_gene[SENSE_START] != -1]\n",
    "len(all_data_human_gene_premrna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7462fb07ce809ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection  import train_test_split, cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "import pandas as pd\n",
    "from data_genertion.consts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed10cd3402c09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_human_gene_premrna_no_nan = all_data_human_gene_premrna.copy()\n",
    "filtered = all_data_human_gene_premrna_no_nan\n",
    "filtered = filtered[filtered['Cell line organism'] == 'human']\n",
    "filtered = filtered[filtered['Cell line organism'] == 'human']\n",
    "print(len(filtered))\n",
    "filtered = filtered.dropna(subset=[INHIBITION]).copy()\n",
    "filtered = filtered.dropna(subset=[DENSITY]).copy()\n",
    "\n",
    "ONE_HOT_FEATURE_NAMES = [CELL_LINE, TRANSFECTION, MODIFICATION, SENSE_TYPE]\n",
    "# append more one-hot features 'first_nucleotide', 'second_nucleotide'\n",
    "\n",
    "for one_hot_feature in ONE_HOT_FEATURE_NAMES:\n",
    "    filtered = pd.get_dummies(filtered, columns=[one_hot_feature]).copy()\n",
    "\n",
    "filtered.loc[:, 'log_volume'] = np.log(filtered[VOLUME])\n",
    "filtered.loc[:, 'log_density'] = np.log(filtered[DENSITY])\n",
    "\n",
    "# more feature generation\n",
    "feature_base = [SENSE_START, SENSE_LENGTH]\n",
    "experiment_features = [VOLUME, 'log_volume', 'log_density', TREATMENT_PERIOD]\n",
    "\n",
    "one_hot_encoded_features = []\n",
    "for one_hot_feature in ONE_HOT_FEATURE_NAMES:\n",
    "    one_hot_encoded_features.append([feature for feature in filtered.columns if one_hot_feature in feature and one_hot_feature != feature])\n",
    "\n",
    "# Flatten the list of list to a single big list\n",
    "flat_one_hot_encoded_features = [feature for sublist in one_hot_encoded_features for feature in sublist]\n",
    "\n",
    "features = feature_base + experiment_features + flat_one_hot_encoded_features\n",
    "\n",
    "train, test = train_test_split(filtered, test_size=0.2)\n",
    "\n",
    "X = train[features]\n",
    "Y = train['log_inhibition']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X[features], train['log_inhibition'])\n",
    "\n",
    "baseline_score = cross_val_score(model, X, Y, cv=5).mean()\n",
    "\n",
    "def spearman_score(y_true, y_pred):\n",
    "    return stats.spearmanr(y_true, y_pred).correlation ** 2\n",
    "\n",
    "spearman_scorer = make_scorer(spearman_score, greater_is_better=True)\n",
    "spearman_score = cross_val_score(model, X, Y, cv=5, scoring=spearman_scorer, n_jobs=-1).mean()\n",
    "\n",
    "print(f\"Baseline score: {baseline_score}\")\n",
    "print(\"Spearman score: \", spearman_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2397032375ce736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_predicted = model.predict(test[features])\n",
    "y_expected = test['log_inhibition']\n",
    "\n",
    "\n",
    "corr, p_value = pearsonr(y_expected, y_predicted)\n",
    "print(\"Pearson Corr: \", corr, \" p_value: \", p_value)\n",
    "corr, p_value = spearmanr(y_expected, y_predicted)\n",
    "print(\"Spearman Corr: \", corr, \" p_value: \", p_value)\n",
    "plt.scatter(y_predicted, y_expected, alpha=0.2)\n",
    "# plt.scatter(y_test, test['gc_content'])\n",
    "x = np.linspace(np.min(y_predicted), np.max(y_predicted), 100)\n",
    "plt.plot(x, x, color='red')\n",
    "\n",
    "plt.xlabel('Predicted Inhibition')\n",
    "plt.ylabel('Actual Inhibition')\n",
    "plt.title('Predicted vs Actual Inhibition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f499709661a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "\n",
    "score, permutation_scores, pvalue = permutation_test_score(model, X, Y, cv=5, n_permutations=100, n_jobs=-1, scoring='r2')\n",
    "print(score, permutation_scores, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b77b868cbed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(filtered[features], filtered['log_inhibition'])\n",
    "\n",
    "# Get the feature importances\n",
    "importances = rf.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbf3e174ed02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in importance_df.iterrows():\n",
    "    print(f\"{row['Feature']:<40} {row['Importance']:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6eeb1c16e58fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's choice of features by leaving one out and calculating the score\n",
    "\n",
    "cv = 5\n",
    "scorer = spearman_scorer\n",
    "jobs = -1\n",
    "feature_importances = []\n",
    "\n",
    "\n",
    "for feature in feature_base:\n",
    "    score_without_feature = cross_val_score(model, X.drop(columns=[feature]), Y, cv=cv, scoring=scorer, n_jobs=jobs).mean()\n",
    "    # print(f\"Dropping {feature}: performance drop = {baseline_score - score_without_feature}\")\n",
    "    feature_importances.append((feature, float(baseline_score - score_without_feature)))\n",
    "\n",
    "print(\"Done base features\")\n",
    "\n",
    "for i in range(len(one_hot_encoded_features)):\n",
    "    feature_name = ONE_HOT_FEATURE_NAMES[i]\n",
    "    feature = one_hot_encoded_features[i]\n",
    "\n",
    "    score_without_feature = cross_val_score(model, X.drop(columns=feature), Y, cv=cv, scoring=scorer, n_jobs=jobs).mean()\n",
    "    performance_diff = baseline_score - score_without_feature\n",
    "    feature_importances.append((feature_name, float(performance_diff)))\n",
    "\n",
    "sorted_data = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "for datum in sorted_data:\n",
    "    print(datum)\n",
    "\n",
    "print(\"The baseline is: \", baseline_score)\n",
    "print(\"The spearman baseline is: \", spearman_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a710e939e3aa106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asodesigner.read_human_genome import get_human_genome_annotation_db, read_human_genome_fasta_dict\n",
    "\n",
    "db = get_human_genome_annotation_db(create_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe12107bec5c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_to_gene_obj = {}\n",
    "\n",
    "for gene in genes_u:\n",
    "    gene_to_gene_obj[gene] = db[gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeefcd67953edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(gene_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a0a42173ebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "asizeof.asizeof(gene_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbcd4c43b464263",
   "metadata": {},
   "outputs": [],
   "source": [
    "asizeof.asizeof(fasta_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676a0605e19ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from consts import HUMAN_DB_BASIC_INTRONS\n",
    "import gffutils\n",
    "\n",
    "db = gffutils.FeatureDB(str(HUMAN_DB_BASIC_INTRONS))\n",
    "db.query('SELECT * ')\n",
    "\n",
    "\n",
    "# gene_feature = db.features_of_type('gene')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0770fd0892705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aso_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
