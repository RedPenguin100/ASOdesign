{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62de4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation on Test Set ===\n",
      "NDCG@all: 0.9770\n",
      "NDCG@5  : 0.7963\n",
      "NDCG@10 : 0.7971\n",
      "Model NDCG: 0.9770, Null NDCG mean: 0.9704, Null NDCG std: 0.0006\n",
      "Model NDCG: 0.9770, p-value: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from asodesigner.consts import *\n",
    "from asodesigner.file_utils import read_human_genome_fasta_dict\n",
    "\n",
    "# Load data\n",
    "all_data = pd.read_csv(DATA_PATH / 'data_from_article_fixed.csv')\n",
    "\n",
    "# Feature engineering\n",
    "all_data['GC_content'] = all_data['Sequence'].str.count('[GC]') / all_data['Sequence'].str.len()\n",
    "all_data['Sequence_length'] = all_data['Sequence'].str.len()\n",
    "\n",
    "# (Optional) check initial structure\n",
    "# print(all_data[['Cell_line', 'ISIS', 'Sequence', 'GC_content', 'Sequence_length', 'Inhibition(%)']].head())\n",
    "\n",
    "# Filter out cell lines with fewer than 300 ASOs\n",
    "min_group_size = 300\n",
    "valid_cell_lines = (\n",
    "    all_data.groupby('Cell_line')\n",
    "    .filter(lambda x: len(x) >= min_group_size)['Cell_line']\n",
    "    .unique()\n",
    ")\n",
    "# Ensure inhibition is finite\n",
    "all_data = all_data[np.isfinite(all_data['Inhibition(%)'])]\n",
    "\n",
    "all_data = all_data[all_data['Cell_line'].isin(valid_cell_lines)]\n",
    "\n",
    "# Split by cell line — group-aware\n",
    "cell_lines = all_data['Cell_line'].unique()\n",
    "train_lines, test_lines = train_test_split(cell_lines, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = all_data['Cell_line'].isin(train_lines)\n",
    "test_mask = ~train_mask\n",
    "\n",
    "# Consistent features for both train and test sets\n",
    "feature_cols = ['ASO_volume(nM)','Treatment_Period(hours)']\n",
    "\n",
    "X_train = all_data.loc[train_mask, feature_cols].values\n",
    "y_train = all_data.loc[train_mask, 'Inhibition(%)'].values\n",
    "group_train = all_data.loc[train_mask].groupby('Cell_line').size().values.tolist()\n",
    "\n",
    "X_test = all_data.loc[test_mask, feature_cols].values\n",
    "y_test = all_data.loc[test_mask, 'Inhibition(%)'].values\n",
    "group_test = all_data.loc[test_mask].groupby('Cell_line').size().values.tolist()\n",
    "\n",
    "# Train XGBRanker\n",
    "ranker = XGBRanker(\n",
    "    objective='rank:pairwise',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "ranker.fit(X_train, y_train, group=group_train)\n",
    "\n",
    "# # 4. Predict and evaluate\n",
    "y_pred = ranker.predict(X_test)\n",
    "\n",
    "# Compute NDCG@all\n",
    "def compute_grouped_ndcg(y_true, y_pred, group_sizes, k=None):\n",
    "    scores = []\n",
    "    start = 0\n",
    "    for size in group_sizes:\n",
    "        end = start + size\n",
    "        if size < 2:\n",
    "            start = end\n",
    "            continue\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "\n",
    "        # Shift y_true to be non-negative\n",
    "        if np.min(yt) < 0:\n",
    "            yt = yt - np.min(yt)\n",
    "\n",
    "        scores.append(ndcg_score([yt], [yp], k=k))\n",
    "        start = end\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "print(\"=== Evaluation on Test Set ===\")\n",
    "\n",
    "print(f\"NDCG@all: {compute_grouped_ndcg(y_test, y_pred, group_test):.4f}\")\n",
    "print(f\"NDCG@5  : {compute_grouped_ndcg(y_test, y_pred, group_test, k=5):.4f}\")\n",
    "print(f\"NDCG@10 : {compute_grouped_ndcg(y_test, y_pred, group_test, k=10):.4f}\")\n",
    "\n",
    "# 5. Compute p-value for NDCG\n",
    "def compute_ndcg_p_value(y_true, group_sizes, y_pred, n_permutations=1000):\n",
    "    model_ndcg = compute_grouped_ndcg(y_true, y_pred, group_sizes)\n",
    "    \n",
    "    null_scores = []\n",
    "    for _ in range(n_permutations):\n",
    "        permuted = []\n",
    "        start = 0\n",
    "        for size in group_sizes:\n",
    "            end = start + size\n",
    "            segment = y_pred[start:end]\n",
    "            permuted.append(np.random.permutation(segment))\n",
    "            start = end\n",
    "        permuted_y_pred = np.concatenate(permuted)\n",
    "        null_scores.append(compute_grouped_ndcg(y_true, permuted_y_pred, group_sizes))\n",
    "\n",
    "  \n",
    "    \n",
    "    null_scores = np.array(null_scores)\n",
    "    p_val = np.mean(null_scores >= model_ndcg) # check if coerent\n",
    "    print(f\"Model NDCG: {model_ndcg:.4f}, Null NDCG mean: {np.mean(null_scores):.4f}, Null NDCG std: {np.std(null_scores):.4f}\")\n",
    "    return model_ndcg, p_val\n",
    "\n",
    "# Example usage\n",
    "model_ndcg, pval = compute_ndcg_p_value(y_test, group_test,\n",
    "                                            ranker.predict(X_test), n_permutations=1000)\n",
    "print(f\"Model NDCG: {model_ndcg:.4f}, p-value: {pval:.4e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cea9970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation on Training Set ===\n",
      "NDCG@all: 0.9461\n",
      "NDCG@5  : 0.7287\n",
      "NDCG@10 : 0.7321\n",
      "Model NDCG (train): 0.9461, p-value: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "y_train_pred = ranker.predict(X_train)\n",
    "\n",
    "print(\"=== Evaluation on Training Set ===\")\n",
    "print(f\"NDCG@all: {compute_grouped_ndcg(y_train, y_train_pred, group_train):.4f}\")\n",
    "print(f\"NDCG@5  : {compute_grouped_ndcg(y_train, y_train_pred, group_train, k=5):.4f}\")\n",
    "print(f\"NDCG@10 : {compute_grouped_ndcg(y_train, y_train_pred, group_train, k=10):.4f}\")\n",
    "\n",
    "# Compute p-value on training predictions\n",
    "model_ndcg_train, pval_train = compute_ndcg_p_value(y_train, group_train, y_train_pred, n_permutations=1000)\n",
    "print(f\"Model NDCG (train): {model_ndcg_train:.4f}, p-value: {pval_train:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954a29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluation on Test Set ===\n",
      "NDCG@all: 0.9770\n",
      "NDCG@5  : 0.7963\n",
      "NDCG@10 : 0.7971\n",
      "Model NDCG: 0.9770, p-value: -6.5455e-03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from asodesigner.consts import *\n",
    "from asodesigner.file_utils import read_human_genome_fasta_dict\n",
    "\n",
    "# Load data\n",
    "all_data = pd.read_csv(DATA_PATH / 'data_from_article_fixed.csv')\n",
    "\n",
    "# Feature engineering\n",
    "all_data['GC_content'] = all_data['Sequence'].str.count('[GC]') / all_data['Sequence'].str.len()\n",
    "all_data['Sequence_length'] = all_data['Sequence'].str.len()\n",
    "\n",
    "# (Optional) check initial structure\n",
    "# print(all_data[['Cell_line', 'ISIS', 'Sequence', 'GC_content', 'Sequence_length', 'Inhibition(%)']].head())\n",
    "\n",
    "# Filter out cell lines with fewer than 300 ASOs\n",
    "min_group_size = 300\n",
    "valid_cell_lines = (\n",
    "    all_data.groupby('Cell_line')\n",
    "    .filter(lambda x: len(x) >= min_group_size)['Cell_line']\n",
    "    .unique()\n",
    ")\n",
    "# Ensure inhibition is finite\n",
    "all_data = all_data[np.isfinite(all_data['Inhibition(%)'])]\n",
    "\n",
    "all_data = all_data[all_data['Cell_line'].isin(valid_cell_lines)]\n",
    "\n",
    "# Split by cell line — group-aware\n",
    "cell_lines = all_data['Cell_line'].unique()\n",
    "train_lines, test_lines = train_test_split(cell_lines, test_size=0.2, random_state=42)\n",
    "\n",
    "train_mask = all_data['Cell_line'].isin(train_lines)\n",
    "test_mask = ~train_mask\n",
    "\n",
    "# Consistent features for both train and test sets\n",
    "feature_cols = ['ASO_volume(nM)','Treatment_Period(hours)']\n",
    "\n",
    "X_train = all_data.loc[train_mask, feature_cols].values\n",
    "y_train = all_data.loc[train_mask, 'Inhibition(%)'].values\n",
    "group_train = all_data.loc[train_mask].groupby('Cell_line').size().values.tolist()\n",
    "\n",
    "X_test = all_data.loc[test_mask, feature_cols].values\n",
    "y_test = all_data.loc[test_mask, 'Inhibition(%)'].values\n",
    "group_test = all_data.loc[test_mask].groupby('Cell_line').size().values.tolist()\n",
    "\n",
    "# Train XGBRanker\n",
    "ranker = XGBRanker(\n",
    "    objective='rank:pairwise',\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "ranker.fit(X_train, y_train, group=group_train)\n",
    "\n",
    "# # 4. Predict and evaluate\n",
    "y_pred = ranker.predict(X_test)\n",
    "\n",
    "# Compute NDCG@all\n",
    "def compute_grouped_ndcg(y_true, y_pred, group_sizes, k=None):\n",
    "    scores = []\n",
    "    start = 0\n",
    "    for size in group_sizes:\n",
    "        end = start + size\n",
    "        if size < 2:\n",
    "            start = end\n",
    "            continue\n",
    "        yt = y_true[start:end]\n",
    "        yp = y_pred[start:end]\n",
    "\n",
    "        # Shift y_true to be non-negative\n",
    "        if np.min(yt) < 0:\n",
    "            yt = yt - np.min(yt)\n",
    "\n",
    "        scores.append(ndcg_score([yt], [yp], k=k))\n",
    "        start = end\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "print(\"=== Evaluation on Test Set ===\")\n",
    "\n",
    "print(f\"NDCG@all: {compute_grouped_ndcg(y_test, y_pred, group_test):.4f}\")\n",
    "print(f\"NDCG@5  : {compute_grouped_ndcg(y_test, y_pred, group_test, k=5):.4f}\")\n",
    "print(f\"NDCG@10 : {compute_grouped_ndcg(y_test, y_pred, group_test, k=10):.4f}\")\n",
    "\n",
    "# 5. Compute p-value for NDCG\n",
    "def compute_ndcg_p_value(y_true, group_sizes, y_pred, n_permutations=1000):\n",
    "    model_ndcg = compute_grouped_ndcg(y_true, y_pred, group_sizes)\n",
    "    \n",
    "    null_scores = []\n",
    "    for _ in range(n_permutations):\n",
    "        permuted = []\n",
    "        start = 0\n",
    "        for size in group_sizes:\n",
    "            end = start + size\n",
    "            segment = y_pred[start:end]\n",
    "            permuted.append(np.random.permutation(segment))\n",
    "            start = end\n",
    "        permuted_y_pred = np.concatenate(permuted)\n",
    "        null_scores.append(compute_grouped_ndcg(y_true, permuted_y_pred, group_sizes))\n",
    "\n",
    "  \n",
    "    \n",
    "    null_scores = np.array(null_scores)\n",
    "    p_val = np.mean(null_scores - model_ndcg) # check if coerent with the original logic\n",
    "    return model_ndcg, p_val\n",
    "\n",
    "# Example usage\n",
    "model_ndcg, pval = compute_ndcg_p_value(y_test, group_test,\n",
    "                                            ranker.predict(X_test), n_permutations=1000)\n",
    "print(f\"Model NDCG: {model_ndcg:.4f}, p-value: {pval:.4e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c01c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ISIS          Sequence Cell_line  GC_content  Sequence_length  \\\n",
      "0  651490  CACTTGTACTAGTATG      A431      0.3750               16   \n",
      "1  651499  GCATTGCTAGTTCAAA      A431      0.3750               16   \n",
      "2  651529  ACTAATAGCAGTGGAA      A431      0.3750               16   \n",
      "3  651540  TTAGGAGTCTTTATAG      A431      0.3125               16   \n",
      "4  651479  GGTGAATATCTTCAAA      A431      0.3125               16   \n",
      "5  540733  GCTAAAACAAATGCTA      A431      0.3125               16   \n",
      "6  540747  TATAATGGTGAATATC      A431      0.2500               16   \n",
      "7  540806  GCATGAAGATTTCTGG      A431      0.4375               16   \n",
      "8  651530  TGACTAATAGCAGTGG      A431      0.4375               16   \n",
      "9  651502  CAACTGCATGCACCAA      A431      0.5000               16   \n",
      "\n",
      "   Inhibition(%)     score  \n",
      "0           36.0 -0.170388  \n",
      "1           46.0 -0.170388  \n",
      "2           27.0 -0.170388  \n",
      "3           30.0 -0.490447  \n",
      "4           28.0 -0.490447  \n",
      "5           33.0 -0.490447  \n",
      "6            7.0 -0.523849  \n",
      "7           62.0 -0.695978  \n",
      "8           58.0 -0.695978  \n",
      "9           31.0 -0.872023  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First 10 ASOs from the all_data DataFrame, keep selected columns\n",
    "raw_data = all_data[['ISIS', 'Cell_line', 'Sequence', 'GC_content', 'Sequence_length', 'Inhibition(%)']].head(10).copy()\n",
    "# sort by inhibition percentage\n",
    "raw_data = raw_data.sort_values(by='Inhibition(%)', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Feature engineering\n",
    "raw_data['GC_content'] = raw_data['Sequence'].str.count('[GC]') / raw_data['Sequence'].str.len()\n",
    "raw_data['Sequence_length'] = raw_data['Sequence'].str.len()\n",
    "\n",
    "# Select features\n",
    "feature_cols = ['GC_content', 'Sequence_length']\n",
    "X_new = raw_data[feature_cols].values\n",
    "\n",
    "# Predict scores\n",
    "raw_data['score'] = ranker.predict(X_new)\n",
    "\n",
    "# Sort by predicted score (descending)\n",
    "df_sorted = raw_data.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Display ranked ASOs\n",
    "print(df_sorted[['ISIS', 'Sequence', 'Cell_line', 'GC_content', 'Sequence_length', 'Inhibition(%)','score']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3351412b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gc_content  purine_content  sequence_length cell_line     score\n",
      "0       0.579           0.469               15      A431  0.233315\n",
      "1       0.588           0.480               18      A431  0.078414\n",
      "2       0.692           0.436               19      A431 -0.191720\n",
      "3       0.574           0.435               19      A431 -0.619765\n",
      "4       0.521           0.412               16      A431 -0.839575\n",
      "5       0.492           0.506               16      A431 -0.953596\n",
      "6       0.391           0.488               15      A431 -1.343866\n",
      "7       0.469           0.548               19      A431 -1.349718\n",
      "8       0.414           0.546               20      A431 -1.743491\n",
      "9       0.457           0.506               20      A431 -1.771293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create dummy ASOs\n",
    "np.random.seed(123)\n",
    "n = 10\n",
    "dummy_asos = pd.DataFrame({\n",
    "    'gc_content': np.round(np.random.uniform(0.3, 0.7, n), 3),\n",
    "    'purine_content': np.round(np.random.uniform(0.4, 0.6, n), 3),\n",
    "    'sequence_length': np.random.randint(15, 21, n),\n",
    "    'cell_line': ['A431'] * n  # Optional\n",
    "})\n",
    "\n",
    "# Step 2: Select features used in training\n",
    "X_dummy = dummy_asos[['gc_content', 'purine_content', 'sequence_length']]\n",
    "\n",
    "# Step 3: Predict ranking scores using your trained model\n",
    "dummy_asos['score'] = ranker.predict(X_dummy)\n",
    "\n",
    "# Step 4: Rank ASOs by model score (higher is better)\n",
    "ranked_asos = dummy_asos.sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(ranked_asos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e02ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aso_design",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
